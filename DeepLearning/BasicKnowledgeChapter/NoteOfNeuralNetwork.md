# Neural Network
## 目录
* 感知机
	> 起源  
	> 权重  
	> 与或非门关系  
	> 多层感知机
* 神经网络
	> 神经网络的层数与感知机的关系  
	> 激活函数  
	> + 阶跃函数
	> + sigmoid
	> + ReLU函数
	> + 恒等函数
	> + softmax函数
	> + 神经网络案例手写数字识别


### 1. 感知机  

见附件2

### 2. 神经网络

Tips.1 神经网络的激活函数必须是非线性函数，使用线性函数是不存在隐藏层

Tips.2 sigmoid函数 h(x) = 1/(1+exp(-x))

Tips.3 ReLU函数 h(x) = max(0, x)

Tips.3 回归问题用恒等函数，二元分类问题用sigmoid函数，多元分类问题可以用softmax函数

Tips.4 输出层用恒等函数σ()

Tips.5 softmax函数 yk = exp(ak) / sum(exp(ai))

Tips.6 机器学习问题的步骤可以分为“学习”和“推理”两个阶段

Tips.7 MNIST数据集是由0-9数字图像构成的，训练集有6万张，测试集有1万张

Tips.8 分类问题的类别等于输出层神经元的数量

Tips.9 输入数据的集合为批